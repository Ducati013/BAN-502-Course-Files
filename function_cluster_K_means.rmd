---
title: "fxn_Kfold"
author: "Kevin Foley"
date: "`r Sys.Date()`"
output: word_document
---


# intro
```{r  all the intro stuff}
library(tidyverse)
library(tidymodels)
library(caret)
library(mice)
library(VIM)
library(ranger)
library(RColorBrewer)
library(rpart)
library(rattle)
library(e1071)
library(xgboost)
library(usemodels)
library(nnet) #our neural network package
library(stacks)
library(vip) #variable importance
```

```{r}
# train = read.csv("C:/Users/ducat/Documents/UNCW_Grad_school/MIS 502 Predictive Analytics/Final Project2/Stacked Final individual pieces/ames_student-1.csv")
# 
# train = train %>% mutate_if(is.character,as_factor) 
# set.seed(123) 
# df_split = initial_split(train, prop = 0.7, strata = Above_Median) #70% in training
# train = training(df_split)
# test = testing(df_split)
# set.seed(123)
# folds = vfold_cv(train, v = 5)
# recipe1 = recipe(Above_Median ~ ., train) %>%  
#                 step_normalize(all_predictors(),- all_nominal()) %>% # normalizes numeric predictors, not needed for categorical
#                 step_dummy(all_nominal(), -all_outcomes()) # to anything that is nominal(), but not the response
#                            # all_numeric_predictors()) #<- another possible
#                         # step_impute_mean(all_numeric_predictors()) %>%
# 
# recipe = recipe(Above_Median ~ Gr_Liv_Area + Year_Built + Full_Bath + First_Flr_SF + Total_Bsmt_SF + Garage_Area + Lot_Area + Garage_Type + Overall_Qual + Garage_Cars, train) %>%
#    step_normalize(all_predictors(),- all_nominal()) %>%
#      step_dummy(all_nominal(), -all_outcomes()) 
#                        
# recipe2 = recipe(Above_Median ~ Gr_Liv_Area + Year_Built + Full_Bath + First_Flr_SF + Total_Bsmt_SF + Garage_Area + Lot_Area + Garage_Type + Overall_Qual + Garage_Cars + Functional +Bsmt_Cond + Bsmt_Qual , train) %>%
#    step_normalize(all_predictors(),- all_nominal()) %>%
#      step_dummy(all_nominal(), -all_outcomes()) 
# recipe3 = recipe(Above_Median ~ Gr_Liv_Area + Year_Built + Full_Bath + First_Flr_SF + Total_Bsmt_SF + Garage_Type + Overall_Qual, train) %>%
#    step_normalize(all_predictors(),- all_nominal()) %>%
#      step_dummy(all_nominal(), -all_outcomes()) 
# 
# ctrl_grid = control_stack_grid() #necessary for working with the stacks package
# ctrl_res = control_stack_resamples() #necessary for working with the stacks package
```


# Load Functions
```{r}

```


# Main()
```{r echo=FALSE}

customers = read_csv("C:/Users/ducat/Documents/UNCW_Grad_school/MIS 502 Predictive Analytics/Mod 6 Unsupervised learning/CustomerData.csv")
customers_scaled = scale(customers)


# begin clustering
set.seed(1234)
clusts =
  tibble(k = 1:10) %>% #try from 1 to 10 clusters
  mutate(
    kclust = map(k, ~kmeans(customers_scaled, .x)),  # (data_frame_scaled_name)
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, customers_scaled)  # (kclust, augment, data_frame_scaled_name)
  )
#clusts

#Create relevant objects
clusters =
  clusts %>%
  unnest(cols = c(tidied))

assignments =
  clusts %>%
  unnest(cols = c(augmented))

clusterings =
  clusts %>%
  unnest(cols = c(glanced))

ggplot(clusterings, aes(k, tot.withinss, label=k)) +
  geom_line() +
  geom_point() + theme_bw()+
  geom_text(hjust=0, vjust=-.5)


cat('how many points?')
input = readline()
cust_clust = kmeans(customers_scaled, centers = input) #run k-means clustering with k = 4
cust_clust #view results

customers = augment(cust_clust, customers)  # this will attach the data to the original data frame, not onto th scaled data..
str(customers)

ggplot(customers, aes(x=Channel,y=Dairy,color=factor(.cluster))) + geom_point() + facet_wrap(~factor(Channel))
```



