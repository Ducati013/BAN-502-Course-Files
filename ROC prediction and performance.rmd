---
title: "ROC prediction and performance"
output: html_document
date: "2023-01-31"
---

```{r}
library(tidyverse)
library(tidymodels)
library(e1071) #often needed for various statistical tasks
library(ROCR) #for threshold selection
library(Hmisc) # for histogram on all columns


credit = read_csv("C:/Users/ducat/Documents/UNCW_Grad_school/MIS 502 Predictive Analytics/Mod 3 Bias& Logistical regression/CSData.csv")
```



```{r factor and clean}

credit = credit %>% mutate(SeriousDlqin2yrs = as_factor(SeriousDlqin2yrs)) %>% 
  mutate(SeriousDlqin2yrs = fct_recode(SeriousDlqin2yrs, "No" = "0", "Yes" = "1" )) 
#hist(credit) # shows histogram of all the columns

credit = credit %>% filter(RevolvingUtilizationOfUnsecuredLines < 2) %>%
  filter(DebtRatio < 5) %>% 
  filter(MonthlyIncome < 20000) %>% drop_na() %>% 
  filter(NumberOfOpenCreditLinesAndLoans < 40) %>%
  filter(NumberOfTimes90DaysLate < 10) %>% 
  filter(NumberRealEstateLoansOrLines < 10) %>% 
  filter(NumberOfDependents < 10)

#hist(credit)  # shows a histogram for all the columns after the filtering
df=credit
```

```{r create Histogram, include=FALSE}

par(mfrow = c(4,2))
for( i in 2:9){
  hist(df[,i], main = colnames(df)[i],xlab = colnames(df)[i], col = 'yellow') # [row,col]
}
```

```{r build model with all factors}
credit_model = 
  logistic_reg(mode = "classification") %>% #note the use of logistic_reg and mode = "classification"
  set_engine("glm") #standard logistic regression engine is glm

credit_recipe = recipe(SeriousDlqin2yrs ~., df)

logreg_wf = workflow() %>%
  add_recipe(credit_recipe) %>% 
  add_model(credit_model)

df_fit = fit(logreg_wf, df)
```

 
```{r Develop predictions }
predictions = predict(df_fit, df, type="prob") #develop predicted probabilities
head(predictions)

predictions = predict(df_fit, df, type="prob")[2]  # this [2] will only pull the second column
head(predictions)
```

  
```{r Threshold selection}
#Change this next line to the names of your predictions and the response variable in the training data frame
ROCRpred = prediction(predictions, credit$SeriousDlqin2yrs) # df$colName

###You shouldn't need to ever change the next two lines:
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7) ,main = "x-axis = 1-specificity & Y-axis = sensitivity")
#this will show the ROC curve, 
```


Area under the curve (AUC). AUC is a measure of the strength of the model. Values closer to 1 are better. Can be used to compare models.  
```{r  Area under Curve}
as.numeric(performance(ROCRpred, "auc")@y.values)   # auc 0f .8157
```

```{r determine threshold  sensitivity and specificity}
#Determine threshold to balance sensitivity and specificity
#DO NOT modify this code
opt.cut = function(perf, pred){
    cut.ind = mapply(FUN=function(x, y, p){
        d = (x - 0)^2 + (y-1)^2
        ind = which(d == min(d))
        c(sensitivity = y[[ind]], specificity = 1-x[[ind]], 
            cutoff = p[[ind]])
    }, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(ROCRperf, ROCRpred))
# print(opt.cut(ROCRperf, ROCRpred)[3,1])  # this will supply the cutoff number [row,col]
```

```{r confusion matrix}
#confusion matrix
#The "No" and "Yes" represent the actual values
#The "FALSE" and "TRUE" represent our predicted values
t0 = table(credit$SeriousDlqin2yrs,predictions > opt.cut(ROCRperf, ROCRpred)[3,1])
# t1 = table(credit$SeriousDlqin2yrs,predictions > 0.06391437)  # the # is the cutoff
# t1
t0
```


```{r accuracy, sensitivity, specificity}
accuracy    = (t0[1,1]+t0[2,2])/nrow(credit)  # # nrow(train)  table[row,col]
sensitivity = (t0[2,2]/(t0[2,1]+t0[2,2]))
specificity = t0[1,1]/(t0[1,1]+t0[1,2])

print( paste("Accuracy    = ", round(accuracy   , digits = 3)*100,'%'))  
print( paste("Sensitivity = ", round(sensitivity, digits = 7)))    
print( paste("Specificity = ", round(specificity, digits = 7)))  

```

Can apply trial and error to maximize accuracy (here trying 0.5 as threshold)
```{r}
t0 = table(credit$SeriousDlqin2yrs,predictions > 0.5)
# t0
# (t0[1,1]+t0[2,2])/nrow(credit)

accuracy    = (t0[1,1]+t0[2,2])/nrow(credit)  # # nrow(train) table[row,col]
sensitivity = (t0[2,2]/(t0[2,1]+t0[2,2]))
specificity = t0[1,1]/(t0[1,1]+t0[1,2])

print( paste("Accuracy    = ", round(accuracy   , digits = 3)*100,'%'))
print( paste("Sensitivity = ", round(sensitivity, digits = 7)))  
print( paste("Specificity = ", round(specificity, digits = 7)))

```

Threshold = 0.6  
```{r}
t0 = table(credit$SeriousDlqin2yrs,predictions > 0.6)
#t0

accuracy    = (t0[1,1]+t0[2,2])/nrow(credit)  # nrow(train)    table[row,col]   
sensitivity = (t0[2,2]/(t0[2,1]+t0[2,2]))
specificity = t0[1,1]/(t0[1,1]+t0[1,2])

print( paste("Accuracy    = ", round(accuracy   , digits = 3)*100,'%'))
print( paste("Sensitivity = ", round(sensitivity, digits = 7)))  
print( paste("Specificity = ", round(specificity, digits = 7)))
```

A naive prediction (everyone not delinquent)
```{r}
t0 = table(credit$SeriousDlqin2yrs,predictions > 1) #set threshold to 1 so all are classified as not delinquent
t0
#(t0[1])/nrow(credit)  # original formula

print(paste('Accuracy = ', round(((t0[1])/nrow(credit)),4)*100,'%'))

```